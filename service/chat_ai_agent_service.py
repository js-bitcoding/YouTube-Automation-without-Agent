from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from langchain.agents import initialize_agent, AgentType
from langchain.tools import Tool
from langchain.memory import ConversationBufferMemory
from langchain_community.llms import Ollama
from database.models import Chat, Group, Document, YouTubeVideo
from database.db_connection import get_db
from fastapi import APIRouter, Depends, HTTPException

# Initialize the Ollama LLM
llm = Ollama(model="llama3.2:1b")

# Setup agent memory
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# Define the tools that will be used by the agent
def fetch_group_data(group_ids: list, db: Session):
    """
    Returns both the formatted string for the LLM and metadata (tone/style info).
    """
    formatted_sections = []
    tone_set = set()
    style_set = set()

    for group_id in group_ids:
        group = db.query(Group).filter(Group.id == group_id).first()
        if not group:
            continue

        section = [f"\n📚 Group: {group.name or 'Unnamed Group'} (ID: {group.id})"]

        documents = db.query(Document).filter(Document.group_id == group_id).all()
        for doc in documents:
            summary = doc.content[:300].strip().replace("\n", " ")
            section.append(f"📄 Document: {doc.filename}\n📝 Summary: {summary}...\n")

        videos = db.query(YouTubeVideo).filter(YouTubeVideo.group_id == group_id).all()
        for video in videos:
            summary = video.transcript[:300].strip().replace("\n", " ")
            tone = video.tone or "Unknown"
            style = video.style or "Unknown"

            tone_set.add(tone.lower())
            style_set.add(style.lower())

            section.append(
                f"🎥 Video: {video.url}\n🗒️ Transcript Snippet: {summary}...\n"
                f"🎙️ Tone: {tone.capitalize()}, ✍️ Style: {style.capitalize()}\n"
            )

        if len(section) > 1:
            formatted_sections.append("\n".join(section))

    return {
        "formatted": "\n\n".join(formatted_sections),
        "tones": list(tone_set),
        "styles": list(style_set)
    }



# Define the tool for the agent
def generate_response_from_prompt_and_data(group_data: str, user_prompt: str):
    """
    This tool takes the group data (either document content or video transcript) and the user prompt,
    and returns a response generated by the LLM.
    """
    prompt = f"Here is some content:\n{group_data}\n\nNow, answer the following prompt:\n{user_prompt}"
    response = llm(prompt)
    return response

# Agent setup with the tools and memory
title_tool = Tool(
    name="ContentBasedAgent",
    func=generate_response_from_prompt_and_data,
    description="Generates a response based on content from documents and YouTube videos based on the group IDs provided by the user."
)

agent = initialize_agent(
    tools=[title_tool],
    llm=llm,
    agent=AgentType.OPENAI_FUNCTIONS,
    verbose=True,
    memory=memory,
    handle_parsing_errors=True
)